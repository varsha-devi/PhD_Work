{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "117bfaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "\n",
    "testDir = \"/home/mrim/quenot/irim/pytorch/dual_encoding_experiments/VisualSearchResults/msrvtt10k/test_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a53393d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpca(a, q=65536):\n",
    "    t0 = time.time()\n",
    "    a = torch.tensor(a)\n",
    "    m = a.mean(axis = 0)\n",
    "    u, s, v = torch.pca_lowrank(a, q=min(a.size(1), q), center=True)\n",
    "    print(time.time()-t0)\n",
    "    return m.numpy(), u.numpy(), s.numpy(), v.numpy()\n",
    "\n",
    "def loadEmbs(testDir, expName, runNum, embsName=\"embs.pth\"):\n",
    "    runDir = os.path.join(testDir, expName, \"runs_%d/model_best\" % runNum)\n",
    "    embs = torch.load(os.path.join(runDir, embsName))\n",
    "    return embs\n",
    "\n",
    "def saveEmbs(embs, testDir, expName, runNum, embsName=\"embs_pca.pth\"):\n",
    "    runDir = os.path.join(testDir, expName,\"runs_%d/model_best\" % runNum)\n",
    "    torch.save(embs, os.path.join(runDir, embsName))\n",
    "\n",
    "def tpca(a, q=65536):\n",
    "    t0 = time.time()\n",
    "    m = a.mean(axis = 0)\n",
    "    u, s, v = torch.pca_lowrank(a, q=min(a.size(1), q), center=True)\n",
    "    print(time.time()-t0)\n",
    "    return m, u, s, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73db7396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.057140111923218\n",
      "6.217867851257324\n",
      "18.99947214126587\n",
      "5.9528820514678955\n",
      "21.471531629562378\n",
      "5.908579111099243\n",
      "17.66382598876953\n",
      "6.103328227996826\n",
      "17.76872491836548\n",
      "6.3718554973602295\n",
      "20.29757595062256\n",
      "5.832735061645508\n",
      "20.626039266586304\n",
      "5.76411247253418\n",
      "21.67258906364441\n",
      "5.553995370864868\n",
      "20.719910144805908\n",
      "5.605205535888672\n",
      "20.31920576095581\n",
      "5.794013023376465\n"
     ]
    }
   ],
   "source": [
    "expName = \"hybrid_1536_512_xin\"\n",
    "nr = 10\n",
    "for n in range(nr):\n",
    "    # print(n)\n",
    "    embs = loadEmbs(testDir, expName, n)\n",
    "    ncap = embs['cap_embs'].shape[0]\n",
    "    nvid = embs['video_embs'].shape[0]\n",
    "    vcl = torch.cat((torch.tensor(embs['cap_embs']), torch.tensor(embs['video_embs'])), dim=0)\n",
    "    vcc = torch.cat((torch.tensor(embs['cap_tag_scores']), torch.tensor(embs['video_tag_scores'])), dim=0)\n",
    "    ml, ul, sl, vl = tpca(vcl)\n",
    "    mc, uc, sc, vc = tpca(vcc)\n",
    "    rvcl = (torch.matmul(vcl-ml, vl))\n",
    "    rvcc = (torch.matmul(vcc-mc, vc))\n",
    "    rcapl, rvidl = rvcl[:ncap,:], rvcl[ncap:,:]\n",
    "    rcapc, rvidc = rvcc[:ncap,:], rvcc[ncap:,:]\n",
    "    embs['cap_embs'], embs['video_embs'] = rcapl.numpy(), rvidl.numpy()\n",
    "    embs['cap_tag_scores'], embs['video_tag_scores'] = rcapc.numpy(), rvidc.numpy()\n",
    "    saveEmbs(embs, testDir, expName, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987c510f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
